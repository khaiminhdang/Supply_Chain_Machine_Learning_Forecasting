
# # PART 2: MACHINE LEARNING FORECASTING
# %% 
# 2.1. Data Importing and Preparation
import pandas as pd
import numpy as np
# Define a function for data importing and pivoting
def import_data():
    """Imports data from a CSV file, creates a 'Period' column, and pivots the dataframe."""
    # Import data from CSV file
    data = pd.read_csv(r"D:\norway_new_car_sales_by_make.csv")
    # Create "Period" column with format YYYY-MM (2007-01)
    data['Period'] = data['Year'].astype(str) + '-' + data['Month'].astype(str).str.zfill(2)
    # Pivot the dataframe
    df = pd.pivot_table(
        data=data,
        values='Quantity',
        index='Make',
        columns='Period',
        aggfunc='sum',
        fill_value=0)
    return df
# Run the function and display the first few rows of the result
df = import_data()
df.head()

# %%
# Data Splitting
# Define a function to split the dataset into train set and test set
# The function takes the dataframe, lengths of x and y, and number of test loops as input parameters
# Machine learning kh√¥ng hi·ªÉu "chu·ªói th·ªùi gian".
# V√¨ v·∫≠y, ta c·∫ßn t·∫°o c√°c t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán v√† ki·ªÉm tra t·ª´ chu·ªói th·ªùi gian ban ƒë·∫ßu
# x_len = 12  # s·ªë th√°ng d√πng l√†m input
# y_len = 1   # s·ªë th√°ng d·ª± ƒëo√°n
# test_loops = 12  # s·ªë v√≤ng d√πng l√†m test
# T√≠nh s·ªë c·ª≠a s·ªï tr∆∞·ª£t (sliding windows). Sliding windows l√† c√°ch t·∫°o ra c√°c t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán v√† ki·ªÉm tra b·∫±ng c√°ch tr∆∞·ª£t m·ªôt c·ª≠a s·ªï qua chu·ªói th·ªùi gian ban ƒë·∫ßu
# Loops (s·ªë c·ª≠a s·ªï tr∆∞·ª£t (sliding windows)) = periods + 1 - x_len - y_len

def datasets(df, x_len=12, y_len=1, test_loops=12):
    """Splits the dataframe into training and testing sets based on the specified lengths and test loops."""
  
    # Get the values and shape of the dataframe
    data_values = df.values
    rows, periods = data_values.shape

    # Total number of loops (including both train and test loops)
    loops = periods + 1 - x_len - y_len

    # Create initial train set
    # Rolling window forecasting: | T1 | T2 | ... | T12 | T13 | ‚Üí X = T1‚ÄìT12 ‚Üí Y = T13. Sau ƒë√≥ tr∆∞·ª£t qua: | T2 | T3 | ... | T13 | T14 |
    # M·ªói h√£ng ƒë·ªÅu t·∫°o window ri√™ng. Sau ƒë√≥ gh√©p t·∫•t c·∫£ c√°c window c·ªßa c√°c h√£ng l·∫°i v·ªõi nhau ƒë·ªÉ t·∫°o th√†nh t·∫≠p train chung
    # T√°ch X v√† Y ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh
    train = []
    for col in range(loops):
        train.append(data_values[:, col:col + x_len + y_len])
    train = np.vstack(train)
    X_train, Y_train = np.split(train, [-y_len], axis=1)

    # Split the initial train set into train set and test set when test_loops is specified
    # rows = s·ªë h√£ng xe
    # test_loops = 12
    # ‚Üí 12 v√≤ng cu·ªëi √ó s·ªë h√£ng ‚Üí ƒë∆∞a v√†o test set. T·ª©c l√† test tr√™n 12 th√°ng g·∫ßn nh·∫•t
    # V√≠ d·ª•: n·∫øu c√≥ 10 h√£ng xe, th√¨ ta s·∫Ω l·∫•y 120 m·∫´u cu·ªëi c√πng l√†m test set
    # C√≤n l·∫°i l√†m train set
    if test_loops > 0:
        X_train, X_test = np.split(X_train, [-rows * test_loops], axis=0)
        Y_train, Y_test = np.split(Y_train, [-rows * test_loops], axis=0)
    else:
        X_test = data_values[:, -x_len:]
        Y_test = np.full((X_test.shape[0], y_len), np.nan)

    # Reformat y_train and y_test to meet scikit-learn requirements
    # Chuy·ªÉn Y th√†nh vector 1 chi·ªÅu
    if y_len == 1:
        Y_train = Y_train.ravel()
        Y_test = Y_test.ravel()

    # Return the train set and test set arrays
    return X_train, Y_train, X_test, Y_test

# Run the function to split the dataset into train set and test set
X_train, Y_train, X_test, Y_test = datasets(df)

# %%
# 2.2. ML Forecasting KPIs
# Define a function to calculate forecasting accuracy KPIs
# RMSE >> MAE ‚Üí c√≥ outlier l·ªõn. Bias = trung b√¨nh sai s·ªë c√≥ d·∫•u
# Bias > 0 ‚Üí Model d·ª± b√°o th·∫•p h∆°n th·ª±c t·∫ø (underforecast) 
# Bias < 0 ‚Üí Model d·ª± b√°o cao h∆°n th·ª±c t·∫ø (overforecast)
# H√†m n√†y t√≠nh to√°n v√† hi·ªÉn th·ªã c√°c ch·ªâ s·ªë MAE, RMSE v√† Bias cho c·∫£ t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra

def kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name=''):
    """Calculate and display MAE, RMSE, and Bias for train and test sets."""

    # Initialize dataframe to store the results
    df = pd.DataFrame(columns=['MAE', 'RMSE', 'Bias'], index=['Train', 'Test'])
    df.index.name = name

    # Calculate metrics for the train set
    df.loc['Train', 'MAE'] = 100 * np.mean(abs(Y_train - Y_train_pred)) / np.mean(Y_train)
    df.loc['Train', 'RMSE'] = 100 * np.sqrt(np.mean((Y_train - Y_train_pred)**2)) / np.mean(Y_train)
    df.loc['Train', 'Bias'] = 100 * np.mean((Y_train - Y_train_pred)) / np.mean(Y_train)

    # Calculate metrics for the test set
    df.loc['Test', 'MAE'] = 100 * np.mean(abs(Y_test - Y_test_pred)) / np.mean(Y_test)
    df.loc['Test', 'RMSE'] = 100 * np.sqrt(np.mean((Y_test - Y_test_pred)**2)) / np.mean(Y_test)
    df.loc['Test', 'Bias'] = 100 * np.mean((Y_test - Y_test_pred)) / np.mean(Y_test)

    # Format the dataframe for better presentation
    df = df.astype(float).round(1)

    # Print the results
    print(df)

# %%
# 2.3. Linear Regression
from sklearn.linear_model import LinearRegression

# Setup model and fit train set
reg = LinearRegression()
reg.fit(X_train, Y_train)

# Forecast and return forecasting accuracy KPIs
# 12 bi·∫øn ùë• x = 12 th√°ng tr∆∞·ªõc. Y = th√°ng ti·∫øp theo ==> Nhu c·∫ßu th√°ng ti·∫øp theo l√† t·ªï h·ª£p tuy·∫øn t√≠nh c·ªßa 12 th√°ng tr∆∞·ªõc
# Autoregressive model v·ªõi ƒë·ªô tr·ªÖ 12 th√°ng (AR(12))
Y_train_pred = reg.predict(X_train)
Y_test_pred = reg.predict(X_test)

kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='Regression')
# %%
# Now use the model to forecast
# Forecast for the future (with test_loops = 0)
# test_loops = 0 ‚Üí kh√¥ng c√≥ test set (Tr∆∞·ªõc ƒë√≥ ta gi·ªØ l·∫°i 12 th√°ng cu·ªëi l√†m test)
# L√∫c n√†y, ta kh√¥ng c√≥ test set n·ªØa v√¨ ta mu·ªën d·ª± b√°o cho nh·ªØng th√°ng ti·∫øp theo sau th√°ng cu·ªëi c√πng trong d·ªØ li·ªáu ban ƒë·∫ßu
# Ta s·∫Ω d√πng to√†n b·ªô d·ªØ li·ªáu ƒë·ªÉ train m√¥ h√¨nh, sau ƒë√≥ d·ª± b√°o cho nh·ªØng th√°ng ti·∫øp theo
# 
X_train_reg, Y_train_reg, X_test_reg, Y_test_reg = datasets(df, x_len=12, y_len=1, test_loops=0)

reg = LinearRegression()
reg.fit(X_train_reg, Y_train_reg)

forecast = pd.DataFrame(
    data=reg.predict(X_test_reg),
    index=df.index,
    columns=['Forecasting result'])
print(forecast.head())

# %%
# 2.4. Decision Tree
# Run Decision Tree Regressor model
from sklearn.tree import DecisionTreeRegressor

# Setup model and fit train set
# C√¢y t·ªëi ƒëa 5 t·∫ßng ‚Üí Gi·ªõi h·∫°n ƒë·ªô ph·ª©c t·∫°p ‚Üí Gi·∫£m overfitting
# M·ªôt node ch·ªâ ƒë∆∞·ª£c chia ti·∫øp n·∫øu c√≥ √≠t nh·∫•t 15 m·∫´u ‚Üí Tr√°nh chia qu√° nh·ªè ‚Üí Tr√°nh noise learning
# M·ªói l√° ph·∫£i c√≥ √≠t nh·∫•t 5 quan s√°t ‚Üí D·ª± b√°o t·∫°i m·ªói l√° = trung b√¨nh c·ªßa √≠t nh·∫•t 5 ƒëi·ªÉm ‚Üí L√†m d·ª± b√°o ·ªïn ƒë·ªãnh h∆°n
# Tree h·ªçc b·∫±ng c√°ch: Ch·ªçn 1 feature (v√≠ d·ª• Y_{t-1}) 
# Ch·ªçn 1 ng∆∞·ª°ng (v√≠ d·ª• 120) & Chia data th√†nh 2 nh√≥m: Nh√≥m ‚â§ 120 Nh√≥m > 120 
# T·ªëi thi·ªÉu h√≥a MSE sau khi chia & L·∫∑p l·∫°i cho t·ª´ng node
# Qu√° tr√¨nh d·ª´ng khi ƒë·∫°t max_depth ho·∫∑c min_samples_split ho·∫∑c min_samples_leaf
# D·ª± b√°o t·∫°i m·ªói l√° = trung b√¨nh c·ªßa c√°c ƒëi·ªÉm trong l√° ƒë√≥
# V√≠ d·ª•: L√° c√≥ 7 ƒëi·ªÉm v·ªõi gi√° tr·ªã Y l√† {100, 110, 120, 130, 140, 150, 160} ‚Üí D·ª± b√°o t·∫°i l√° n√†y = (100+110+120+130+140+150+160)/7 = 130
# C√¢y c√†ng s√¢u, c√†ng nhi·ªÅu l√° ‚Üí D·ª± b√°o c√†ng chi ti·∫øt ‚Üí Nh∆∞ng d·ªÖ overfitting
# Decision Tree l√† m√¥ h√¨nh phi tuy·∫øn + no formula + easy to be overfit + capture natural interaction ‚Üí M√¥ h√¨nh h√≥a c√°c quan h·ªá ph·ª©c t·∫°p h∆°n Linear Regression

tree = DecisionTreeRegressor(max_depth=5, min_samples_split=15, min_samples_leaf=5)
tree.fit(X_train, Y_train)

# Forecast and return forecasting accuracy KPIs
Y_train_pred = tree.predict(X_train)
Y_test_pred = tree.predict(X_test)

kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='Tree')

# %%
# Visualize the tree

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

# Create figure and axis for the tree visualization
fig = plt.figure(figsize=(15, 6), dpi=300)
ax = fig.add_subplot(111)

# Visualize the tree and save as an image
plot_tree(tree, fontsize=3, feature_names=[f'M{x-12}' for x in range(12)],
          rounded=True, filled=True, ax=ax)
fig.savefig('Regression_Tree.PNG')

# %%
# Forecast accuracy and time comparison between criterion MSE and MAE
# Nghƒ©a l√† so s√°nh gi·ªØa vi·ªác s·ª≠ d·ª•ng MSE (squared_error) v√† MAE (absolute_error) l√†m ti√™u ch√≠ chia node trong c√¢y quy·∫øt ƒë·ªãnh
# MSE nh·∫°y c·∫£m v·ªõi outlier l·ªõn, trong khi MAE √≠t nh·∫°y c·∫£m h∆°n v·ªõi outlier
# Vi·ªác so s√°nh n√†y gi√∫p hi·ªÉu r√µ h∆°n v·ªÅ ·∫£nh h∆∞·ªüng c·ªßa ti√™u ch√≠ chia node
# ƒê·ªìng th·ªùi, ƒëo th·ªùi gian hu·∫•n luy·ªán ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa t·ª´ng ti√™u ch√≠

import time
# Dictionary to store results
results = []

# Loop through different criteria
# Ghi l·∫°i th·ªùi ƒëi·ªÉm b·∫Øt ƒë·∫ßu
for criterion in ['squared_error', 'absolute_error']:
    start_time = time.time()

    # Initialize and fit the model
    # Thi·∫øt l·∫≠p v√† hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi ti√™u ch√≠ hi·ªán t·∫°i
    tree = DecisionTreeRegressor(
        max_depth=5, min_samples_split=15, min_samples_leaf=5, criterion=criterion)
    tree.fit(X_train, Y_train)

    # Predict and evaluate KPIs
    Y_train_pred = tree.predict(X_train)
    Y_test_pred = tree.predict(X_test)
    kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name=f'Tree {criterion}')
    print()

    # Record training time
    # ‚Üí Th·ªùi gian = th·ªùi ƒëi·ªÉm hi·ªán t·∫°i - l√∫c b·∫Øt ƒë·∫ßu
    training_time = time.time() - start_time
    results.append([criterion, training_time])

# Convert results to DataFrame for easier comparison
# L∆∞u training time v√† convert sang DataFrame ƒë·ªÉ d·ªÖ so s√°nh
results_df = pd.DataFrame(results, columns=['Criterion', 'Training Time (seconds)'])
print(results_df)

# %%
# 2.5. Parameter Optimization (Decision Tree examples)
# Use Randomized Search with Cross-Validation to optimize Decision Tree parameters
# T·ªëi ∆∞u h√≥a tham s·ªë c·ªßa Decision Tree b·∫±ng c√°ch s·ª≠ d·ª•ng Randomized Search k·∫øt h·ª£p v·ªõi Cross-Validation

from sklearn.model_selection import RandomizedSearchCV
# Parameter grid
# max_depth 5 ‚Üí 10: c√¢y t·ª´ v·ª´a ƒë·∫øn s√¢u. None: kh√¥ng gi·ªõi h·∫°n ƒë·ªô s√¢u
# min_samples_split 5 ‚Üí 20: m·ªói node ph·∫£i c√≥ √≠t nh·∫•t 5-20 m·∫´u m·ªõi ƒë∆∞·ª£c chia ti·∫øp
# min_samples_leaf 2 ‚Üí 20: m·ªói l√° ph·∫£i c√≥ √≠t nh·∫•t 2-20 m·∫´u

max_depth = list(range(5, 11)) + [None]
min_samples_split = range(5, 20)
min_samples_leaf = range(2, 20)
# Sau ƒë√≥ gom l·∫°i th√†nh dictionary param_dist ƒê√¢y l√† kh√¥ng gian ƒë·ªÉ Random Search th·ª≠ nghi·ªám
# M·ªói l·∫ßn th·ª≠ nghi·ªám, Random Search s·∫Ω ch·ªçn ng·∫´u nhi√™n m·ªôt t·ªï h·ª£p c√°c tham s·ªë t·ª´ param_dist ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh v√† ƒë√°nh gi√° hi·ªáu su·∫•t b·∫±ng Cross-Validation
param_dist = {
    'max_depth': max_depth,
    'min_samples_split': min_samples_split,
    'min_samples_leaf': min_samples_leaf}

# Setup model
# Initialize Decision Tree Regressor (Kh·ªüi t·∫°o model c∆° b·∫£n), sau ƒë√≥ RandomizedSearchCV s·∫Ω t√¨m tham s·ªë t·ªët nh·∫•t d·ª±a tr√™n kh√¥ng gian param_dist
tree = DecisionTreeRegressor()

# Apply K-Fold Cross-Validation & Random Search with MAE scoring
# RandomizedSearchCV s·∫Ω th·ª≠ nghi·ªám 100 t·ªï h·ª£p tham s·ªë kh√°c nhau (n_iter=100) (Kh√¥ng th·ª≠ h·∫øt to√†n b·ªô t·ªï h·ª£p. V√¨ s·ªë t·ªï h·ª£p qu√° l·ªõn)
# S·ª≠ d·ª•ng 10-fold Cross-Validation (cv=10) ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa m·ªói t·ªï h·ª£p tham s·ªë
# S·ª≠ d·ª•ng MAE l√†m ti√™u ch√≠ ƒë√°nh gi√° (scoring='neg_mean_absolute_error')
# 10-fold cross validation | Quy tr√¨nh: Chia d·ªØ li·ªáu th√†nh 10 ph·∫ßn & Train tr√™n 9 ph·∫ßn. Test tr√™n 1 ph·∫ßn L·∫∑p l·∫°i 10 l·∫ßn 
# L·∫•y trung b√¨nh MAE ‚Üí Gi·∫£m r·ªßi ro ph·ª• thu·ªôc 1 c√°ch chia train/test
# scoring='neg_mean_absolute_error' => Tr·∫£ v·ªÅ gi√° tr·ªã √¢m c·ªßa MAE v√¨ sklearn t·ªëi ∆∞u h√≥a h√†m ƒëi·ªÉm s·ªë sao cho c√†ng l·ªõn c√†ng t·ªët 
# Trong khi MAE c√†ng nh·ªè c√†ng t·ªët ‚Üí ƒê·ªïi d·∫•u ƒë·ªÉ ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa sklearn
# verbose=1 ‚Üí Hi·ªÉn th·ªã ti·∫øn tr√¨nh c·ªßa qu√° tr√¨nh t√¨m ki·∫øm
tree_cv = RandomizedSearchCV(
    estimator=tree, param_distributions=param_dist, n_iter=100,
    scoring='neg_mean_absolute_error', n_jobs=-1, cv=10, verbose=1)
tree_cv.fit(X_train, Y_train)

# Output the best parameters and score
print('Tuned Regression Tree Parameters:', tree_cv.best_params_)
print('Best Cross-Validation MAE:', -tree_cv.best_score_)  # Negate to get positive MAE

# %%
# Use the tuned model with optimized parameters to forecast and return forecasting accuracy KPIs
# tree_cv kh√¥ng c√≤n l√† c√¢y m·∫∑c ƒë·ªãnh n·ªØa m√† sau khi .fit(), n√≥: ƒê√£ ch·∫°y 100 random c·∫•u h√¨nh + ƒê√£ ch·ªçn b·ªô tham s·ªë t·ªët nh·∫•t + T·ª± ƒë·ªông refit l·∫°i model tr√™n to√†n b·ªô X_train v·ªõi best params 
# N√™n: tree_cv.predict() = d√πng c√¢y t·ªëi ∆∞u r·ªìi
# L·∫•y m√¥ h√¨nh v·ªõi tham s·ªë t·ªëi ∆∞u t·ª´ RandomizedSearchCV ƒë·ªÉ d·ª± b√°o v√† ƒë√°nh gi√° KPIs
y_train_pred = tree_cv.predict(X_train)
y_test_pred = tree_cv.predict(X_test)

kpi_ML(Y_train, y_train_pred, Y_test, y_test_pred, name='Tree Tuned')
print()

# Check the detail K-Fold Cross-Validation & Random Search result
cv_result = pd.DataFrame(tree_cv.cv_results_)
print(cv_result.head())

# %%
# 2.6. Random Forest
# Train Random Forest v·ªõi tham s·ªë c·ªë ƒë·ªãnh
# Random Forest L√† trung b√¨nh d·ª± b√°o c·ªßa nhi·ªÅu Decision Tree
# M·ªói tree h·ªçc tr√™n 1 m·∫´u con (bootstrap sample) c·ªßa t·∫≠p hu·∫•n luy·ªán (M·ªói c√¢y ƒë∆∞·ª£c train tr√™n m·∫´u random c√≥ l·∫∑p (sampling with replacement ƒë·ªÉ t·∫°o s·ª± kh√°c bi·ªát gi·ªØa c√°c c√¢y v√† gi·∫£m variance))
# M·ªói l·∫ßn chia node, ch·ªâ ch·ªçn 1 t·∫≠p con c·ªßa c√°c bi·∫øn: M·ªói c√¢y ch·ªâ d√πng 95% d·ªØ li·ªáu train ‚Üí tƒÉng randomness ‚Üí gi·∫£m overfitting
# M·ªói node ch·ªâ ƒë∆∞·ª£c ch·ªçn 11 feature ƒë·ªÉ split ‚Üí l√†m c√°c c√¢y kh√°c nhau ‚Üí gi·∫£m correlation gi·ªØa c√¢y
# M·ªôt leaf ph·∫£i c√≥ √≠t nh·∫•t 18 ƒëi·ªÉm & max_depth=7 Gi·ªõi h·∫°n ƒë·ªô s√¢u c√¢y ‚Üí ngƒÉn overfitting
from sklearn.ensemble import RandomForestRegressor
# Setup model and fit train set
forest = RandomForestRegressor(
    bootstrap=True,
    max_samples=0.95,
    max_features=11,
    min_samples_leaf=18,
    max_depth=7)
forest.fit(X_train, Y_train)

# Forecast and return forecasting accuracy KPIs
Y_train_pred = forest.predict(X_train)
Y_test_pred = forest.predict(X_test)
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='Forest')

# %%
# Parameter optimization with n_estimators=30
# Random Forest c√≥ nhi·ªÅu tham s·ªë (hyperparameter) h∆°n Decision Tree ƒë·ªÉ t·ªëi ∆∞u h√≥a, bao g·ªìm: max_depth, min_samples_split, min_samples_leaf, max_features, bootstrap, max_samples ·∫£nh h∆∞·ªüng ƒë·∫øn: Bias Variance Stability Speed
# Tuning Random Forest ==> RandomizedSearchCV th·ª≠ 400 t·ªï h·ª£p ng·∫´u nhi√™n: n_iter=400 v√† cv=6 ==> 400 c·∫•u h√¨nh M·ªói c·∫•u h√¨nh ch·∫°y 6 folds = 2400 l·∫ßn train model
# Parameter grid
max_depth = list(range(5, 11)) + [None]
min_samples_split = range(5, 20)
min_samples_leaf = range(2, 15)
max_features = range(3, 8)
bootstrap = [True]
max_samples = [.7, .8, .9, .95, 1]
param_dist = {
    'max_depth': max_depth,
    'min_samples_split': min_samples_split,
    'min_samples_leaf': min_samples_leaf,
    'max_features': max_features,
    'bootstrap': bootstrap,
    'max_samples': max_samples}

# Apply K-Fold Cross-Validation & Random Search with MAE scoring to the model
forest = RandomForestRegressor(n_jobs=1, n_estimators=30)
forest_cv = RandomizedSearchCV(
    estimator=forest,
    param_distributions=param_dist,
    cv=6,
    n_jobs=-1,
    verbose=2,
    n_iter=400,
    scoring='neg_mean_absolute_error')
forest_cv.fit(X_train, Y_train)
print('Tuned Forest Parameters:', forest_cv.best_params_)

# Use the tuned model with optimized parameters to forecast and return forecasting accuracy KPIs
Y_train_pred = forest_cv.predict(X_train)
Y_test_pred = forest_cv.predict(X_test)
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='Forest optimized')

# %%
# Parameter optimization with n_estimators=200
# Use the tuned model with optimized parameters and n_estimators = 200 to forecast and return forecasting accuracy KPIs
# TƒÉng n_estimators t·ª´ 30 l√™n 200 ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ·ªïn ƒë·ªãnh v√† ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh
# S·ªë l∆∞·ª£ng c√¢y c√†ng nhi·ªÅu, d·ª± b√°o c√†ng ·ªïn ƒë·ªãnh v√† ch√≠nh x√°c h∆°n, nh∆∞ng th·ªùi gian hu·∫•n luy·ªán c≈©ng tƒÉng l√™n
# D√πng tham s·ªë t·ªëi ∆∞u t·ª´ b∆∞·ªõc tr∆∞·ªõc (Gi·ªØ to√†n b·ªô c·∫•u h√¨nh t·ªëi ∆∞u ƒë√£ t√¨m ƒë∆∞·ª£c), ch·ªâ thay n_estimators = 200
# Random Forest kh√¥ng overfit khi tƒÉng s·ªë c√¢y

forest = RandomForestRegressor(n_estimators=200, n_jobs=-1, **forest_cv.best_params_)
forest = forest.fit(X_train, Y_train)
Y_train_pred = forest.predict(X_train)
Y_test_pred = forest.predict(X_test)
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='Forest n_estimators = 200')

# %%
# 2.7. Feature Importance (Random Forest examples)
# Xem m√¥ h√¨nh Random Forest ‚Äúƒëang d·ª±a v√†o th√°ng n√†o nhi·ªÅu nh·∫•t‚Äù ƒë·ªÉ d·ª± b√°o
# --> Th√°ng n√†o trong qu√° kh·ª© ·∫£nh h∆∞·ªüng m·∫°nh nh·∫•t ƒë·∫øn d·ª± b√°o th√°ng ti·∫øp theo
# Random Forest t√≠nh importance d·ª±a tr√™n: T·ªïng m·ª©c gi·∫£m impurity (MSE) do m·ªói feature t·∫°o ra
# Khi m·ªôt feature ƒë∆∞·ª£c d√πng ƒë·ªÉ split: N·∫øu n√≥ l√†m gi·∫£m MSE nhi·ªÅu V√† ƒë∆∞·ª£c d√πng nhi·ªÅu l·∫ßn ‚Üí importance cao
# Number of train features
cols = X_train.shape[1]

# Get the feature list
features = [f'M-{cols - col}' for col in range(cols)]

# Create the feature importance dataframe
feature_importance = pd.DataFrame(data=forest.feature_importances_.reshape(-1, 1),
                                  index=features,
                                  columns=['Forest'])

# Visualize the feature importance chart
feature_importance.plot(kind='bar')

# %%
# 2.8. Extremely Randomized Trees/Extra Trees
# Random Forest ‚Üí Extra Trees (Extremely Randomized Trees)
# Extra trees t∆∞∆°ng t·ª± Random Forest, nh∆∞ng c√≥ th√™m ƒë·ªô ng·∫´u nhi√™n:
# Chia node b·∫±ng c√°ch ch·ªçn ng∆∞·ª°ng split ng·∫´u nhi√™n thay v√¨ t√¨m ng∆∞·ª°ng t·ªëi ∆∞u
# Gi√∫p gi·∫£m variance h∆°n n·ªØa ‚Üí M√¥ h√¨nh ·ªïn ƒë·ªãnh h∆°n n·ªØa
# Tuy nhi√™n, do tƒÉng ƒë·ªô ng·∫´u nhi√™n n√™n bias c√≥ th·ªÉ tƒÉng nh·∫π

# Gi·∫£i th√≠ch th√™m v·ªÅ Extra Trees
# Random Forest: Ch·ªçn subset feature ng·∫´u nhi√™n Nh∆∞ng v·∫´n t√¨m best split t·ªëi ∆∞u (gi·∫£m MSE nhi·ªÅu nh·∫•t)
# Extra Trees: Ch·ªçn feature ng·∫´u nhi√™n V√† c√≤n ch·ªçn ng∆∞·ª°ng split ng·∫´u nhi√™n lu√¥n Kh√¥ng t√¨m best threshold

from sklearn.ensemble import ExtraTreesRegressor
# Setup the model
# Extra Trees v·∫´n l√† ensemble c·ªßa nhi·ªÅu decision trees nh∆∞ng c√≥ th√™m ƒë·ªô ng·∫´u nhi√™n trong vi·ªác ch·ªçn ng∆∞·ª°ng split
ETR = ExtraTreesRegressor(n_jobs=-1, n_estimators=200, min_samples_split=15,
                          min_samples_leaf=4, max_samples=0.95, max_features=4,
                          max_depth=8, bootstrap=True)

# Fit train set to the model
ETR.fit(X_train, Y_train)

# Use the model to predict train and test sets
Y_train_pred = ETR.predict(X_train)
Y_test_pred = ETR.predict(X_test)

# Return forecasting accuracy KPIs
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='ETR')

# %%
# Parameter optimization with n_estimators=30 - Tuning v·ªõi n_estimators=30
# T·ªëi ∆∞u h√≥a tham s·ªë c·ªßa Extra Trees b·∫±ng c√°ch s·ª≠ d·ª•ng Randomized Search k·∫øt h·ª£p v·ªõi Cross-Validation
# # Parameter grid
max_depth = list(range(6, 13)) + [None]
min_samples_split = range(7, 16)
min_samples_leaf = range(2, 13)
max_features = range(5, 13)
bootstrap = [True]
max_samples = [.7, .8, .9, .95, 1]

param_dist = {'max_depth': max_depth,
              'min_samples_split': min_samples_split,
              'min_samples_leaf': min_samples_leaf,
              'max_features': max_features,
              'bootstrap': bootstrap,
              'max_samples': max_samples}

ETR = ExtraTreesRegressor(n_jobs=1, n_estimators=30)
ETR_cv = RandomizedSearchCV(ETR, param_dist, cv=5, verbose=2, n_jobs=-1,
                            n_iter=400, scoring='neg_mean_absolute_error')
ETR_cv.fit(X_train, Y_train)

print('Tuned Forest Parameters:', ETR_cv.best_params_)

# Use the tuned model to predict train and test sets
Y_train_pred = ETR_cv.predict(X_train)
Y_test_pred = ETR_cv.predict(X_test)
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='ETR optimized')

# %%
# Parameter optimization with n_estimators=200 - Tuning v·ªõi n_estimators=200
# Use the tuned model with optimized parameters and n_estimators = 200 to forecast and return forecasting accuracy KPIs
# Run the tuned model with 200 trees
ETR = ExtraTreesRegressor(n_estimators=200, n_jobs=-1, **ETR_cv.best_params_).fit(X_train, Y_train)
Y_train_pred = ETR.predict(X_train)
Y_test_pred = ETR.predict(X_test)
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='ETR x200')

# %%
# 2.9. Feature Optimization #1 (Random Forest and Extremely Randomized Trees examples)
# Feature optimization: Ch·ªçn ra c√°c bi·∫øn quan tr·ªçng nh·∫•t ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh
# Gi√∫p gi·∫£m ƒë·ªô ph·ª©c t·∫°p m√¥ h√¨nh, tƒÉng t·ªëc ƒë·ªô hu·∫•n luy·ªán, v√† c√≥ th·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t n·∫øu lo·∫°i b·ªè ƒë∆∞·ª£c c√°c bi·∫øn kh√¥ng quan tr·ªçng

# Determine the optimal number of feature using train set
# hay l√† s·ªë th√°ng d√πng l√†m input (D√πng bao nhi√™u th√°ng qu√° kh·ª© (bao nhi√™u lag) l√† t·ªëi ∆∞u?)
# T·ª©c l√† ƒëang t·ªëi ∆∞u feature space, kh√¥ng ph·∫£i hyperparameter n·ªØa

# Get the dataframe
df = import_data()

# Define RandomForestRegressor parameters
# Test v·ªõi: Random Forest Extra Trees & gi·ªØ hyperparameter c·ªë ƒë·ªãnh (ƒë√£ t·ªëi ∆∞u t·ª´ tr∆∞·ªõc)
forest_features = {
    "n_jobs": -1,
    "n_estimators": 200,
    "min_samples_split": 15,
    "min_samples_leaf": 4,
    "max_samples": 0.95,
    "max_features": 0.3,
    "max_depth": 8,
    "bootstrap": True
}
forest = RandomForestRegressor(**forest_features)

# Define ExtraTreesRegressor parameters
etr_features = {
    "n_jobs": -1,
    "n_estimators": 200,
    "min_samples_split": 14,
    "min_samples_leaf": 2,
    "max_samples": 0.9,
    "max_features": 1.0,
    "max_depth": 12,
    "bootstrap": True
}
etr = ExtraTreesRegressor(**etr_features)

# List of models
models = [("Forest", forest), ("ETR", etr)]

# Create function to return MAE
# Sai s·ªë t∆∞∆°ng ƒë·ªëi so v·ªõi quy m√¥ d·ªØ li·ªáu
# MAE% = Mean Absolute Error / Mean Actual Value
def model_mae(model, X, y):
    y_pred = model.predict(X)
    mae = np.mean(np.abs(y - y_pred)) / np.mean(y)
    return mae

# Define range for months (from 6 to 50 with a 2-month gap)
# S·ªë th√°ng d√πng l√†m input (feature) t·ª´ 6 ƒë·∫øn 50, b∆∞·ªõc nh·∫£y 2 th√°ng
# T·ª©c l√† s·∫Ω th·ª≠ v·ªõi 6, 8, 10, ..., 48
n_months = range(6, 50, 2)

# Empty list to store the results
results = []

# Train and test models to find the optimal number of features
# M·ªói l·∫ßn: T·∫°o b·ªô feature m·ªõi S·ªë c·ªôt X thay ƒë·ªïi M√¥ h√¨nh ph·∫£i h·ªçc l·∫°i
# L∆∞u l·∫°i MAE% cho train v√† test set
for x_len in n_months:
    X_train, Y_train, X_test, Y_test = datasets(df, x_len=x_len)

    for name, model in models:
        model.fit(X_train, Y_train)
        mae_train = model_mae(model, X_train, Y_train)
        mae_test = model_mae(model, X_test, Y_test)

        results.append([f"{name} Train", mae_train, x_len])
        results.append([f"{name} Test", mae_test, x_len])

# Format results into a DataFrame for visualization
data = pd.DataFrame(results, columns=["Model", "MAE%", "Number of Months"])
data = data.set_index(["Number of Months", "Model"]).stack().unstack("Model")
data.index = data.index.droplevel(level=1)
data.index.name = "Number of Months"

# Visualize the results
data.plot(color=["orange"] * 2 + ["black"] * 2, style=["-", "--"] * 2)
plt.xlabel("Number of Months")
plt.ylabel("MAE%")
plt.title("Model Performance Across Different Time Periods")
plt.show()

# Print the optimal number of features
print(data.idxmin())

# %%
# 2.10. Adaptive Boosting/AdaBoost
# Kh√°c v·ªõi Random Forest v√† Extra Trees l√† x√¢y d·ª±ng nhi·ªÅu c√¢y ƒë·ªôc l·∫≠p r·ªìi l·∫•y trung b√¨nh d·ª± b√°o
# AdaBoost x√¢y d·ª±ng c√°c c√¢y theo chu·ªói, m·ªói c√¢y sau t·∫≠p trung s·ª≠a l·ªói c·ªßa c√¢y tr∆∞·ªõc 
# Qu√° tr√¨nh n√†y gi√∫p m√¥ h√¨nh h·ªçc t·ª´ c√°c l·ªói tr∆∞·ªõc ƒë√≥ v√† c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c d·ª± b√°o
# M·ªói c√¢y trong chu·ªói ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh tr·ªçng s·ªë ƒë·ªÉ t·∫≠p trung v√†o c√°c ƒëi·ªÉm d·ªØ li·ªáu m√† c√¢y tr∆∞·ªõc ƒë√≥ d·ª± b√°o sai
# Cu·ªëi c√πng, d·ª± b√°o c·ªßa t·∫•t c·∫£ c√°c c√¢y ƒë∆∞·ª£c k·∫øt h·ª£p l·∫°i ƒë·ªÉ t·∫°o th√†nh d·ª± b√°o cu·ªëi c√πng
# AdaBoost th∆∞·ªùng s·ª≠ d·ª•ng c√°c c√¢y n√¥ng (shallow trees) l√†m weak learners ƒë·ªÉ tr√°nh overfitting v√† gi·ªØ m√¥ h√¨nh ƒë∆°n gi·∫£n
# Vi·ªác k·∫øt h·ª£p nhi·ªÅu weak learners gi√∫p m√¥ h√¨nh t·ªïng th·ªÉ m·∫°nh m·∫Ω h∆°n v√† c√≥ kh·∫£ nƒÉng t·ªïng qu√°t h√≥a t·ªët h∆°n tr√™n d·ªØ li·ªáu m·ªõi
# AdaBoost ph√π h·ª£p cho c√°c b√†i to√°n d·ª± b√°o ph·ª©c t·∫°p, n∆°i m√† c√°c m√¥ h√¨nh ƒë∆°n l·∫ª c√≥ th·ªÉ kh√¥ng ƒë·ªß m·∫°nh ƒë·ªÉ n·∫Øm b·∫Øt c√°c m·∫´u trong d·ªØ li·ªáu
# Tr∆∞·ªõc ƒë√¢y d√πng: Bagging (song song, gi·∫£m variance) --> B√¢y gi·ªù d√πng: Boosting (tu·∫ßn t·ª±, gi·∫£m bias)
# Boosting: K·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh y·∫øu (weak learners) th√†nh m√¥ h√¨nh m·∫°nh (strong learner)

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor

# DecisionTreeRegressor(max_depth=8) --> ƒê√¢y l√† base learner
# n_estimators=100 S·ªë l∆∞·ª£ng c√¢y ƒë∆∞·ª£c build tu·∫ßn t·ª±
# learning_rate=0.25 T·ªëc ƒë·ªô h·ªçc (learning rate) ki·ªÉm so√°t m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa m·ªói c√¢y m·ªõi ƒë∆∞·ª£c th√™m v√†o m√¥ h√¨nh
# Nh·ªè ‚Üí h·ªçc ch·∫≠m ‚Üí ·ªïn ƒë·ªãnh h∆°n
# L·ªõn ‚Üí h·ªçc nhanh ‚Üí d·ªÖ overfit
ada = AdaBoostRegressor(DecisionTreeRegressor(max_depth=8), n_estimators=100, learning_rate=0.25, loss='square')
ada = ada.fit(X_train, Y_train)

Y_train_pred = ada.predict(X_train)
Y_test_pred = ada.predict(X_test)
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='AdaBoost')

# %%
# Parameter optimization
# Parameter grid
n_estimators = [100]
learning_rate = [0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]
loss = ['square', 'exponential', 'linear']

param_dist = {# 'n_estimators': n_estimators,  # Uncomment decide to test this parameter
              'learning_rate': learning_rate,
              'loss': loss}

from sklearn.model_selection import RandomizedSearchCV

# List to store results
results = []

# Loop over different max_depth values
for max_depth in range(2, 18, 2):
    ada = AdaBoostRegressor(DecisionTreeRegressor(max_depth=max_depth))
    ada_cv = RandomizedSearchCV(ada, param_dist, n_jobs=-1, cv=6, n_iter=20, scoring='neg_mean_absolute_error')
    ada_cv.fit(X_train, Y_train)
    print(f'Tuned AdaBoost Parameters for max_depth={max_depth}:', ada_cv.best_params_)
    print('Result:', ada_cv.best_score_)

    # Store the results
    results.append([ada_cv.best_score_, ada_cv.best_params_, max_depth])

# Convert results to DataFrame for easy visualization
results_df = pd.DataFrame(results, columns=['Best Score', 'Best Parameters', 'Max Depth'])
print(results_df)

# Convert the results to DataFrame
results = pd.DataFrame(data=results, columns=['Score', 'Best Params', 'Max Depth'])

# Find the index of the maximum score
# best_score_ = neg_mean_absolute_error ‚Üí Gi√° tr·ªã c√†ng g·∫ßn 0 c√†ng t·ªët
optimal = results['Score'].idxmax()

# Print the row corresponding to the optimal score
print(results.iloc[optimal])

# %%
# Test the optimized model with loss function linear to check the result
ada = AdaBoostRegressor(
    DecisionTreeRegressor(max_depth=8),
    n_estimators=100,
    learning_rate=0.005,
    loss="linear",)

ada.fit(X_train, Y_train)
y_train_pred = ada.predict(X_train)
y_test_pred = ada.predict(X_test)
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name="AdaBoost optimized")

# %%
# Use AdaBoost with MultiOutputRegressor to forecast multiple output values
from sklearn.multioutput import MultiOutputRegressor

multi = MultiOutputRegressor(ada, n_jobs=-1)
X_train, Y_train, X_test, Y_test = datasets(df, x_len=12, y_len=6, test_loops=12)
multi.fit(X_train, Y_train)

# %%
# 2.11. Demand Drivers and Leading Indicators
# Import dataset
df = import_data()
GDP = pd.read_excel("C:\\Users\\DELL\\Downloads\\GDP.xlsx").set_index('Year')
dates = pd.to_datetime(df.columns,format='%Y-%m').year
X_GDP = [GDP.loc[date,'GDP'] for date in dates]

# Define a function to split the dataset into train set and test set (with exogenous data input)
# √ù t∆∞·ªüng: Tr∆∞·ªõc gi·ªù ch·ªâ d√πng: pure time series (autoregressive) ==> D·ª± b√°o d·ª±a tr√™n ch√≠nh d·ªØ li·ªáu qu√° kh·ª© c·ªßa n√≥
# B√¢y gi·ªù, ta s·∫Ω th√™m v√†o c√°c y·∫øu t·ªë b√™n ngo√†i (exogenous variables)
# D·ª± b√°o demand kh√¥ng ch·ªâ d·ª±a v√†o demand qu√° kh·ª© m√† c√≤n d·ª±a v√†o y·∫øu t·ªë kinh t·∫ø vƒ© m√¥ (GDP)

def datasets_exo(df, X_exo, x_len=12, y_len=1, test_loops=12):

  # Get the value and shape of the dataframe
  D = df.values
  rows, periods = D.shape

  # Reshape X_exo to a row then repeat that row multiple times to reach the amount of rows in the dataframe
  X_exo = np.repeat(np.reshape(X_exo,[1,-1]), rows, axis=0)

  # Create an array X_months that contains the last month of each period then repeat it multiple times to reach the amount of rows in the dataframe
  X_months = np.repeat(np.reshape([int(col[-2:]) for col in df.columns], [1,-1]), rows, axis=0)

  # Total number of loops, including train and test in the dataset
  loops = periods + 1 - x_len - y_len

  # Create train set and test set
  # For each column in total loop, take all data from that column to the column at the end of a loop (13 months)
  # m = X_months[:,col+x_len] -- m ‚Üí th√°ng hi·ªán t·∫°i
  # exo = X_exo[:,col:col+x_len] -- exo ‚Üí GDP c·ªßa x_len th√°ng tr∆∞·ªõc
  # d = D[:,col:col+x_len+y_len] -- d ‚Üí lag demand
  # XGBoost l√† Gradient Boosting n√¢ng c·∫•p
  # AdaBoost: Update weight sample + Kh√¥ng regularization m·∫°nh + √çt t·ªëi ∆∞u h√≥a
  # XGBoost: Fit residual + Regularization m·∫°nh + Nhi·ªÅu t·ªëi ∆∞u h√≥a h∆°n

  train = []
  for col in range(loops):
    m = X_months[:,col+x_len].reshape(-1,1) #month
    exo = X_exo[:,col:col+x_len] #exogenous data
    d = D[:,col:col+x_len+y_len]
    train.append(np.hstack([m, exo, d]))
  train = np.vstack(train)
  X_train, Y_train = np.split(train,[-y_len],axis=1)

  # If test_loops is required, split the X_train, Y_train above to train set and test set
  # Else, X_test is used to generate the future forecast and Y_test contains dummy values
  if test_loops > 0:
    X_train, X_test = np.split(X_train, [-rows*test_loops], axis = 0)
    Y_train, Y_test = np.split(Y_train, [-rows*test_loops], axis = 0)
  else:
    X_test = np.hstack([m[:,-1].reshape(-1,1),X_exo[:,-x_len:],D[:,-x_len:]])
    Y_test = np.full((X_test.shape[0], y_len), np.nan)

  # Reformat Y_train and Y_test to meet scikit-learn requirement
  if y_len == 1:
    Y_train = Y_train.ravel()
    Y_test = Y_test.ravel()

  # Return test set and train set
  return X_train, Y_train, X_test, Y_test

# %%
# 2.12. Extreme Gradient Boosting/XGBoost
# 2.12.1. Run the model
from xgboost.sklearn import XGBRegressor
XGB = XGBRegressor(
    n_jobs=-1,
    max_depth=10,
    n_estimators=100,
    learning_rate=0.2)
XGB = XGB.fit(X_train, Y_train)

# 2.12.2. Feature Importance

# Gain = t·ªïng m·ª©c gi·∫£m loss do feature ƒë√≥ g√¢y ra
# Kh√°c Random Forest: RF importance = gi·∫£m MSE trung b√¨nh c√≤n XGB importance = t·ªïng gain qua boosting rounds
# Gain ph·∫£n √°nh m·ª©c ƒë·ªô quan tr·ªçng th·ª±c s·ª± c·ªßa feature trong vi·ªác c·∫£i thi·ªán hi·ªáu su·∫•t m√¥ h√¨nh
# Gain ƒë∆∞·ª£c t√≠nh to√°n b·∫±ng c√°ch t·ªïng h·ª£p m·ª©c gi·∫£m loss (v√≠ d·ª•: MSE) m√† m·ªói feature ƒë√≥ng g√≥p trong qu√° tr√¨nh x√¢y d·ª±ng c√°c c√¢y quy·∫øt ƒë·ªãnh trong m√¥ h√¨nh XGBoost
# Feature v·ªõi gain cao ‚Üí quan tr·ªçng h∆°n ‚Üí model d·ª±a v√†o nhi·ªÅu h∆°n ƒë·ªÉ d·ª± b√°o

import xgboost as xgb
XGB.get_booster().feature_names = [f'M{x-12}' for x in range(12)]
xgb.plot_importance(XGB, importance_type='total_gain', show_values=False)

# %%

# 2.12.3. Use XGBoost with MultiOutputRegressor to forecast multiple output values

# N√¢ng y_len = 6 == > D·ª± b√°o 6 th√°ng ti·∫øp theo c√πng l√∫c
from sklearn.multioutput import MultiOutputRegressor

# Training and testing
# Multi-step forecasting: Direct strategy (M·ªói horizon c√≥ model ri√™ng) and Recursive strategy (D·ª± b√°o t+1 r·ªìi d√πng n√≥ d·ª± b√°o t+2)
X_train, Y_train, X_test, Y_test = datasets(
    df, x_len=12, y_len=6, test_loops=12)
XGB = XGBRegressor(
    n_jobs=1,
    max_depth=10,
    n_estimators=100,
    learning_rate=0.2)
multi = MultiOutputRegressor(XGB, n_jobs=-1)
multi.fit(X_train, Y_train)

# Future forecast
# Nghƒ©a l√†: Train tr√™n to√†n b·ªô l·ªãch s·ª≠ T·∫°o X_test l√† 12 th√°ng cu·ªëi D·ª± b√°o 6 th√°ng t∆∞∆°ng lai
# 12 th√°ng cu·ªëi kh√¥ng d√πng l√†m test set n·ªØa m√† d√πng ƒë·ªÉ t·∫°o input X_test cho vi·ªác d·ª± b√°o t∆∞∆°ng lai
X_train, Y_train, X_test, Y_test = datasets(
    df, x_len=12, y_len=6, test_loops=0)
XGB = XGBRegressor(
    n_jobs=1,
    max_depth=10,
    n_estimators=100,
    learning_rate=0.2)
multi = MultiOutputRegressor(XGB, n_jobs=-1)
multi.fit(X_train, Y_train)
forecast = pd.DataFrame(data=multi.predict(X_test), index=df.index)
forecast.head()

# %%
# 2.12.4. Early Stopping when reaching the minimal loss function value of evaluation set
from sklearn.model_selection import train_test_split

x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.15)

XGB = XGBRegressor(n_jobs=-1,
                   max_depth=10,
                   n_estimators=1000,
                   learning_rate=0.01,
                   objective='reg:absoluteerror',
                   early_stopping_rounds=100)

# Only use validation set for early stoppping evaluation
XGB = XGB.fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False)
print(f'Using validation set for evaluation')
print(f'Best iteration: {XGB.get_booster().best_iteration}')
print(f'Best score: {XGB.get_booster().best_score}')
print()

# Use both train set and validation set for early stoppping evaluation
XGB = XGB.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_val, y_val)], verbose=False)
print(f'Using train set and validation set for evaluation')
print(f'Best iteration: {XGB.get_booster().best_iteration}')
print(f'Best score: {XGB.get_booster().best_score}')
print()

# Use holdout set for early stoppping evaluation
X_train, Y_train, X_holdout, Y_holdout, X_test, Y_test = datasets_holdout(
    df, x_len=12, y_len = 1, test_loops = 12, holdout_loops = 12
)

XGB = XGB.fit(X_train, Y_train, eval_set=[(X_holdout, Y_holdout)], verbose=False)
print(f'Using holdout set for evaluation')
print(f'Best iteration: {XGB.get_booster().best_iteration}')
print(f'Best score: {XGB.get_booster().best_score}')
print()

# %%
# 2.12.5. (PENDING) Early Stopping for XGBoost with MultiOutputRegressor --> Cannot use eval_set with MultiOutputRegressor
from sklearn.multioutput import MultiOutputRegressor
X_train, Y_train, X_test, Y_test = datasets(
    df, x_len=12, y_len=6, test_loops=0)

x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.15)

XGB = XGBRegressor(
    n_jobs=1,
    max_depth=10,
    n_estimators=100,
    learning_rate=0.2,
    objective='reg:absoluteerror',
    early_stopping_rounds=25,)
multi = MultiOutputRegressor(XGB, n_jobs=-1)
multi.fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False)

# %%
# 2.12.6. Parameter optimization
# Train, test, and validation sets
X_train, Y_train, X_test, Y_test = datasets(
    df, x_len=12, y_len=6, test_loops=12)
x_train, x_val, y_train, y_val = train_test_split(
    X_train, Y_train, test_size=0.15)

# Parameter grid
params = {
    'max_depth': [5, 6, 7, 8, 10, 11],
    'learning_rate': [0.005, 0.01, 0.025, 0.05, 0.1, 0.15],
    'colsample_bynode': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bylevel': [0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7],
    'min_child_weight': [5, 10, 15, 20, 25],
    'reg_alpha': [1, 5, 10, 20, 50],
    'reg_lambda': [0.01, 0.05, 0.1, 0.5, 1],
    'n_estimators': [1000],}

# Set up model
XGB = XGBRegressor(
    n_jobs=1, early_stopping_rounds=25, objective='reg:absoluteerror')

# Random Search
XGB_cv = RandomizedSearchCV(
    XGB,
    params,
    cv=5,
    n_jobs=-1,
    verbose=1,
    n_iter=1000,
    scoring='neg_mean_absolute_error',)
XGB_cv.fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False)
print('Tuned XGBoost Parameters:', XGB_cv.best_params_)

# %%
# Train the final model with optimized parameters
best_params = XGB_cv.best_params_

XGB = XGBRegressor(
    n_jobs=-1,
    early_stopping_rounds=25,
    objective='reg:absoluteerror',
    **best_params)

XGB.fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False)

# Print best iteration and score
print(f'Best iteration: {XGB.get_booster().best_iteration}')
print(f'Best score: {XGB.get_booster().best_score}')

# Make predictions and evaluate performance
Y_train_pred = XGB.predict(X_train)
Y_test_pred = XGB.predict(X_test)
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='XGBoost')

# %%
# 2.13. Categorical Features
# 2.13.1. Integer Encoding
# Define the segment for each car brand
luxury = [
    'Aston Martin', 'Bentley', 'Ferrari', 'Lamborghini', 'Lexus', 'Lotus',
    'Maserati', 'McLaren', 'Porsche', 'Tesla']

premium = [
    'Audi', 'BMW', 'Cadillac', 'Infiniti', 'Land Rover',
    'MINI', 'Mercedes-Benz', 'Jaguar']

low_cost = ['Dacia', 'Skoda']

# Encode the segments to integer data
df['Segment'] = 2

mask = df.index.isin(luxury)
df.loc[mask, 'Segment'] = 4

mask = df.index.isin(premium)
df.loc[mask, 'Segment'] = 3

mask = df.index.isin(low_cost)
df.loc[mask, 'Segment'] = 1

# Assign each brand with each integer
df['Brand'] = df.index
df['Brand'] = df['Brand'].astype('category').cat.codes
df.head()

# %%
# 2.13.2. One-hot Encoding
df['Brand'] = df.index
df = pd.get_dummies(df, columns=['Brand'])
df.head()

# 2.13.3. Dataset Creation
# Define a function to split the dataset into train and test sets with a categorical column
def datasets_cat(df, x_len=12, y_len=1, test_loops=12, cat_name='_'):
    """
    Splits the dataframe into training and testing sets based on the specified
    lengths and test loops, considering categorical columns.
    """

    # Identify categorical columns and get dataset shape
    col_cat = [col for col in df.columns if cat_name in col]
    data_values = df.drop(columns=col_cat).values  # Historical demand
    categorical_values = df[col_cat].values  # Categorical info
    rows, periods = data_values.shape

    # Total number of loops (train + test)
    loops = periods + 1 - x_len - y_len

    # Create the training set
    train = [data_values[:, col:col + x_len + y_len] for col in range(loops)]
    train = np.vstack(train)
    X_train, Y_train = np.split(train, [-y_len], axis=1)
    X_train = np.hstack((np.vstack([categorical_values] * loops), X_train))

    # Split into train and test sets
    if test_loops > 0:
        X_train, X_test = np.split(X_train, [-rows * test_loops], axis=0)
        Y_train, Y_test = np.split(Y_train, [-rows * test_loops], axis=0)
    else:
        X_test = np.hstack((categorical_values, data_values[:, -x_len:]))
        Y_test = np.full((X_test.shape[0], y_len), np.nan)

    # Reshape Y_train and Y_test for scikit-learn compatibility
    if y_len == 1:
        Y_train = Y_train.ravel()
        Y_test = Y_test.ravel()

    return X_train, Y_train, X_test, Y_test

# %%
# Apply Integer Encoding
df = import_data()
df['Segment'] = 2

mask = df.index.isin(luxury)
df.loc[mask, 'Segment'] = 4

mask = df.index.isin(premium)
df.loc[mask, 'Segment'] = 3

mask = df.index.isin(low_cost)
df.loc[mask, 'Segment'] = 1

X_train, Y_train, X_test, Y_test = datasets_cat(
    df, x_len=12, y_len=1, test_loops=12, cat_name='Segment')

# %%
# Apply One-Hot Encoding
df['Brand'] = df.index
df = pd.get_dummies(df, columns=['Brand'], prefix_sep='_')

X_train, Y_train, X_test, Y_test = datasets_cat(
    df, x_len=12, y_len=1, test_loops=12, cat_name='_')

# %%
# 2.14. Clustering
# Define function to get the multiplicative seasonal factor for each period
def seasonal_factors(df, slen):
    s = pd.DataFrame(index=df.index)
    for i in range(slen):
        s[i + 1] = df.iloc[:, i::slen].mean(axis=1)

    s = s.divide(s.mean(axis=1), axis=0).fillna(0)
    return s

# Define function to Scale the seasonal factor to a range of 0 to 1
def scaler(s):
    mean = s.mean(axis=1)
    maxi = s.max(axis=1)
    mini = s.min(axis=1)
    s = s.subtract(mean, axis=0)
    s = s.divide(maxi - mini, axis=0).fillna(0)
    return s

# Apply for the dataset
df = import_data()
s = seasonal_factors(df,slen=12)
s = scaler(s)
print(s.head())

# %%
# from sklearn.cluster import KMeans

# Perform KMeans clustering with 4 clusters
kmeans = KMeans(n_clusters=4, random_state=0).fit(s)
df['Group'] = kmeans.predict(s)

# Evaluate KMeans with different cluster numbers
results = []
for n in range(1, 10):
    kmeans = KMeans(n_clusters=n, random_state=0).fit(s)
    results.append([n, kmeans.inertia_])

# Convert results to DataFrame and plot
results = pd.DataFrame(
    data=results, columns=['Number of clusters', 'Inertia']
).set_index('Number of clusters')

results.plot()

# %%
import calendar
import seaborn as sns

# Perform KMeans clustering with 4 clusters
kmeans = KMeans(n_clusters=4, random_state=0).fit(s)

# Create a DataFrame for cluster centers
centers = pd.DataFrame(data=kmeans.cluster_centers_).transpose()
centers.index = calendar.month_abbr[1:]
centers.columns = [f'Cluster {x}' for x in range(centers.shape[1])]

# Plot heatmap of cluster centers
sns.heatmap(centers, annot=True, fmt='.2f', center=0, cmap='RdBu_r')

# Print value counts of each group
print(df['Group'].value_counts().sort_index())

# %%
# 2.15. Feature Optimization #2 
def datasets_full(
    df, X_exo, x_len=12, y_len=1, test_loops=12, holdout_loops=0, cat_name=['_']):
    '''
    Generates training, holdout, and test datasets for time series forecasting.

    Parameters:
    df (pd.DataFrame): DataFrame containing historical demand data.
    X_exo (np.array): Exogenous variables affecting demand.
    x_len (int): Number of past periods used as features (default: 12).
    y_len (int): Forecast horizon (default: 1).
    test_loops (int): Number of test samples (default: 12).
    holdout_loops (int): Number of holdout samples (default: 0).
    cat_name (list): List of substrings indicating categorical columns (default: ['_']).

    Returns:
    tuple: (X_train, Y_train, X_holdout, Y_holdout, X_test, Y_test, features)
    '''

    # Identify categorical columns based on specified substrings in column names
    col_cat = [col for col in df.columns if any(name in col for name in cat_name)]
    categorical_values = df[col_cat].values  # Extract categorical data
    data_values = df.drop(columns=col_cat).values  # Extract numerical demand data
    rows, periods = data_values.shape  # Number of rows (items) and periods (time steps)

    # Repeat exogenous variables for each row in the dataset
    X_exo = np.repeat(np.reshape(X_exo, [1, -1]), rows, axis=0)

    # Extract month information from column names (assumed last 2 characters represent the month)
    X_months = np.repeat(
        np.reshape(
            [int(col[-2:]) for col in df.columns if col not in col_cat], [1, -1]
        ),
        rows,
        axis=0,)

    # Training set creation
    loops = periods + 1 - x_len - y_len  # Number of rolling windows
    train = []

    for col in range(loops):
        m = X_months[:, col + x_len].reshape(-1, 1)  # Extract month as a feature
        exo = X_exo[:, col : col + x_len + y_len]  # Select exogenous variables

        # Aggregate exogenous features
        exo = np.hstack(
            [
                np.mean(exo, axis=1, keepdims=True),  # Mean of all exogenous data
                np.mean(exo[:, -4:], axis=1, keepdims=True),  # Mean of last 4 months
                exo,
            ])

        d = data_values[:, col : col + x_len + y_len]  # Extract demand data

        # Aggregate demand features
        d = np.hstack(
            [
                np.mean(d[:, :-y_len], axis=1, keepdims=True),  # Mean demand
                np.median(d[:, :-y_len], axis=1, keepdims=True),  # Median demand
                np.mean(d[:, -4 - y_len : -y_len], axis=1, keepdims=True),  # 4-month MA
                np.max(d[:, :-y_len], axis=1, keepdims=True),  # Max demand
                np.min(d[:, :-y_len], axis=1, keepdims=True),  # Min demand
                d,])

        # Append all features to the training dataset
        train.append(np.hstack([m, exo, d]))

    train = np.vstack(train)  # Stack training samples into a single array
    X_train, Y_train = np.split(train, [-y_len], axis=1)  # Split features and target

    # Include categorical values in the feature matrix
    X_train = np.hstack((np.vstack([categorical_values] * loops), X_train))

    # Define feature names
    features = (
        col_cat
        + ['Month']
        + ['Exo Mean', 'Exo MA4']
        + [f'Exo M{-x_len+col}' for col in range(x_len + y_len)]
        + [
            'Demand Mean',
            'Demand Median',
            'Demand MA4',
            'Demand Max',
            'Demand Min',]
        + [f'Demand M-{x_len-col}' for col in range(x_len)])

    # Holdout set creation
    if holdout_loops > 0:
        X_train, X_holdout = np.split(X_train, [-rows * holdout_loops], axis=0)
        Y_train, Y_holdout = np.split(Y_train, [-rows * holdout_loops], axis=0)
    else:
        X_holdout, Y_holdout = np.array([]), np.array([])

    # Test set creation
    if test_loops > 0:
        X_train, X_test = np.split(X_train, [-rows * test_loops], axis=0)
        Y_train, Y_test = np.split(Y_train, [-rows * test_loops], axis=0)
    else:  # No test set: X_test is used to generate future forecasts
        exo = X_exo[:, -x_len - y_len :]
        d = data_values[:, -x_len:]

        X_test = np.hstack(
            (
                categorical_values,
                m[:, -1].reshape(-1, 1),  # Latest available month
                np.hstack(
                    [
                        np.mean(exo, axis=1, keepdims=True),
                        np.mean(exo[:, -4:], axis=1, keepdims=True),
                        exo,]),
                np.hstack(
                    [
                        np.mean(d, axis=1, keepdims=True),
                        np.median(d, axis=1, keepdims=True),
                        np.mean(d[:, -4:], axis=1, keepdims=True),
                        np.max(d, axis=1, keepdims=True),
                        np.min(d, axis=1, keepdims=True),
                        d,]),))
        Y_test = np.full((X_test.shape[0], y_len), np.nan)  # Dummy values for prediction

    # Format target variables for scikit-learn (flatten if y_len = 1)
    if y_len == 1:
        Y_train = Y_train.ravel()
        Y_test = Y_test.ravel()
        Y_holdout = Y_holdout.ravel()

    return X_train, Y_train, X_holdout, Y_holdout, X_test, Y_test, features

# Import dataset
df = import_data()

# Load GDP data and set 'Year' as the index
GDP = pd.read_excel('GDP.xlsx').set_index('Year')

# Extract year information from the column names of df
dates = pd.to_datetime(df.columns, format='%Y-%m').year

# Map GDP values to corresponding years in df
X_GDP = [GDP.loc[date, 'GDP'] for date in dates]

# Define vehicle brand segments
luxury = [
    'Aston Martin', 'Bentley', 'Ferrari', 'Lamborghini', 'Lexus', 'Lotus',
    'Maserati', 'McLaren', 'Porsche', 'Tesla']

premium = [
    'Audi', 'BMW', 'Cadillac', 'Infiniti', 'Land Rover',
    'MINI', 'Mercedes-Benz', 'Jaguar']

low_cost = ['Dacia', 'Skoda']

# Default all brands to segment 2
df['Segment'] = 2

# Assign segment values based on brand category
df.loc[df.index.isin(luxury), 'Segment'] = 4
df.loc[df.index.isin(premium), 'Segment'] = 3
df.loc[df.index.isin(low_cost), 'Segment'] = 1

# Store brand names in a new column
df['Brand'] = df.index

# Convert 'Brand' into one-hot encoded features
df = pd.get_dummies(df, columns=['Brand'], prefix_sep='_')


from sklearn.model_selection import train_test_split

# Generate datasets for training, holdout, and testing
X_train, Y_train, X_holdout, Y_holdout, X_test, Y_test, features = datasets_full(
    df, X_GDP, x_len=12, y_len=1, test_loops=12, holdout_loops=0,
    cat_name=['_', 'Segment', 'Group']
)

# Split the training dataset into training and validation sets (15% for validation)
x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.15)


from xgboost.sklearn import XGBRegressor

# Initialize XGBoost Regressor with specified hyperparameters
XGB = XGBRegressor(
    n_jobs=-1,
    max_depth=10,
    n_estimators=1000,
    learning_rate=0.01,
    objective='reg:absoluteerror',
    early_stopping_rounds=100
)

# Train the model using the validation set for early stopping evaluation
XGB = XGB.fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False)

# Make predictions on training and test sets
Y_train_pred = XGB.predict(X_train)
Y_test_pred = XGB.predict(X_test)

# Evaluate model performance
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='XGBoost')


# Get feature importance from the trained XGBoost model
imp = XGB.get_booster().get_score(importance_type='total_gain')

# Convert importance dictionary to a DataFrame
imp = pd.DataFrame.from_dict(imp, orient='index', columns=['Importance'])

# Map feature indices to actual feature names
imp.index = np.array(features)[
    imp.index.astype(str).str.replace('f', '').astype(int)
]

# Normalize importance values and sort in descending order
imp = (imp['Importance'] / sum(imp.values)).sort_values(ascending=False)

# Save feature importance to an Excel file
imp.to_excel('Feature Importance.xlsx')

# Display the top features
imp.head()


def model_kpi(model, X, Y):
    """
    Calculate MAE and RMSE as a percentage of the mean actual values.

    Parameters:
    model: Trained model with a predict method.
    X (array-like): Feature matrix.
    Y (array-like): True target values.

    Returns:
    tuple: (MAE, RMSE) as relative error percentages.
    """
    Y_pred = model.predict(X)
    mae = np.mean(np.abs(Y - Y_pred)) / np.mean(Y)
    rmse = np.sqrt(np.mean((Y - Y_pred) ** 2)) / np.mean(Y)

    return mae, rmse


# Initialize an empty list to store results
results = []

# Define the list of limits for filtering features
limits = [
    0.00005, 0.0001, 0.00015, 0.0002, 0.00025, 0.0003, 0.0004,
    0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.001, 0.0011, 0.002, 0.004,
    0.008, 0.01, 0.02, 0.04, 0.06
]

# Initialize the XGBRegressor model with specific hyperparameters
XGB = XGBRegressor(
    n_jobs=-1,                    # Use all available cores for parallelism
    max_depth=10,                 # Maximum depth of the trees
    n_estimators=1000,            # Number of boosting rounds
    learning_rate=0.01,           # Step size shrinking
    objective='reg:absoluteerror', # Objective function
    early_stopping_rounds=100     # Stop early if no improvement after 100 rounds
)

# Iterate over each limit to filter features and train the model
for limit in limits:
    # Create a mask to filter features based on importance
    mask = [feature in imp[imp > limit] for feature in features]

    # Train the model using the filtered features
    XGB = XGB.fit(
        x_train[:, mask],
        y_train,
        verbose=False,
        eval_set=[(x_val[:, mask], y_val)]
    )

    # Append the model performance metrics to the results
    results.append(model_kpi(XGB, x_val[:, mask], y_val))

# Convert results into a DataFrame with proper columns and index
results = pd.DataFrame(data=results, columns=['MAE', 'RMSE'], index=limits)

# Plot the results with MAE on the secondary y-axis and log scale on x-axis
results.plot(secondary_y='MAE', logx=True)


# Define the limit for filtering the importance values
limit = 0.007

# Print the index of features with importance greater than the limit
print(imp[imp > limit].index)


# Create a mask to filter features based on importance
mask = [feature in imp[imp > limit] for feature in features]

# Train the XGB model using the filtered features
XGB = XGB.fit(
    x_train[:, mask],
    y_train,
    verbose=False,
    eval_set=[(x_val[:, mask], y_val)]
)

# Predict the target variable for training and test datasets
Y_train_pred = XGB.predict(X_train[:, mask])
Y_test_pred = XGB.predict(X_test[:, mask])

# Calculate and print the performance metrics using KPI function
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='XGBoost')


# %%
# 2.16. Neural Network

from sklearn.neural_network import MLPRegressor
NN = MLPRegressor().fit(X_train, Y_train)

# Neural Network Parameters
hidden_layer_sizes = [
    [neuron] * hidden_layer
    for neuron in range(10, 60, 10)
    for hidden_layer in range(2, 7)]
alpha = [5, 1, 0.5, 0.1, 0.05, 0.01, 0.001]
learning_rate_init = [0.05, 0.01, 0.005, 0.001, 0.0005]
beta_1 = [0.85, 0.875, 0.9, 0.95, 0.975, 0.99, 0.995]
beta_2 = [0.99, 0.995, 0.999, 0.9995, 0.9999]
param_dist = {
    'hidden_layer_sizes': hidden_layer_sizes,
    'alpha': alpha,
    'learning_rate_init': learning_rate_init,
    'beta_1': beta_1,
    'beta_2': beta_2}

# Adam Parameters
activation = 'relu'
solver = 'adam'
early_stopping = True
n_iter_no_change = 50
validation_fraction = 0.1
tol = 0.0001

param_fixed = {
    'activation': activation,
    'solver': solver,
    'early_stopping': early_stopping,
    'n_iter_no_change': n_iter_no_change,
    'validation_fraction': validation_fraction,
    'tol': tol}

# Run NN with Adam optimizer
NN = MLPRegressor(hidden_layer_sizes=(20,20), **param_fixed, verbose=True).fit(X_train, Y_train)

# Using Random Search to test NN parameter to find the best model
NN = MLPRegressor(**param_fixed)
NN_cv = RandomizedSearchCV(NN, param_dist, cv=10, verbose=2, n_jobs=-1, n_iter=200, scoring='neg_mean_absolute_error')
NN_cv.fit(X_train, Y_train)
print('Tuned NN Parameters:', NN_cv.best_params_)
print()
Y_train_pred = NN_cv.predict(X_train)
Y_test_pred = NN_cv.predict(X_test)
kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='NN optimized')